{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBhaXEskgtdN",
        "outputId": "56ddfe5a-fe68-4761-89f5-5883d376a07c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df_original = pd.read_csv('/content/drive/MyDrive/CO544/transformed_rainfall_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your dataframe is named 'df'\n",
        "df = df_original[~df_original.index.isin([0, 1])]"
      ],
      "metadata": {
        "id": "-RApT8oWoKuJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Assuming your data is loaded into a DataFrame named 'df'\n",
        "\n",
        "# Convert the date column to datetime format\n",
        "df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
        "\n",
        "# Extracting day of the year as a feature\n",
        "df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "\n",
        "# Select features and target\n",
        "features = ['DayOfYear']\n",
        "targets = ['Vavuniya', 'Anuradhapura', 'Maha Illuppallama']\n",
        "\n",
        "# Feature engineering\n",
        "\n",
        "# Lag features (previous day's value)\n",
        "for target in targets:\n",
        "  df[f'{target}_lag1'] = df[target].shift(1)\n",
        "\n",
        "# Rolling mean (weekly window)\n",
        "window_size = 7  # You can experiment with different window sizes\n",
        "for target in targets:\n",
        "  df[f'{target}_rolling_mean_{window_size}'] = df[target].rolling(window=window_size).mean()\n",
        "\n",
        "# Month and Weekday features\n",
        "# df['Month'] = df['Date'].dt.month\n",
        "# df['Is_Weekend'] = np.where(df['Date'].dt.weekday_name.isin(['Saturday', 'Sunday']), 1, 0)\n",
        "\n",
        "# After feature engineering\n",
        "df.dropna(inplace=True)  # Drop rows with any NaN values\n",
        "\n",
        "# Splitting the data into training and testing sets\n",
        "X = df[features + [col for col in df.columns if col.endswith('_lag1') or col.endswith(f'_rolling_mean_{window_size}')]]  # Include engineered features\n",
        "y_vavuniya = df['Vavuniya']\n",
        "y_anuradhapura = df['Anuradhapura']\n",
        "y_maha = df['Maha Illuppallama']\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train_v, y_test_v = train_test_split(X, y_vavuniya, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train_a, y_test_a = train_test_split(X, y_anuradhapura, test_size=0.2, random_state=42)\n",
        "X_train, X_test, y_train_m, y_test_m = train_test_split(X, y_maha, test_size=0.2, random_state=42)\n",
        "\n",
        "# ... (rest of your code for training and prediction)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q10JjawT6LH",
        "outputId": "1047b446-b256-47cb-adde-24aef1553a1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ab9b7845a373>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['Date'] = pd.to_datetime(df['Date'], format='%Y%m%d')\n",
            "<ipython-input-8-ab9b7845a373>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['DayOfYear'] = df['Date'].dt.dayofyear\n",
            "<ipython-input-8-ab9b7845a373>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[f'{target}_lag1'] = df[target].shift(1)\n",
            "<ipython-input-8-ab9b7845a373>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[f'{target}_lag1'] = df[target].shift(1)\n",
            "<ipython-input-8-ab9b7845a373>:21: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[f'{target}_lag1'] = df[target].shift(1)\n",
            "<ipython-input-8-ab9b7845a373>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[f'{target}_rolling_mean_{window_size}'] = df[target].rolling(window=window_size).mean()\n",
            "<ipython-input-8-ab9b7845a373>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[f'{target}_rolling_mean_{window_size}'] = df[target].rolling(window=window_size).mean()\n",
            "<ipython-input-8-ab9b7845a373>:26: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df[f'{target}_rolling_mean_{window_size}'] = df[target].rolling(window=window_size).mean()\n",
            "<ipython-input-8-ab9b7845a373>:33: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df.dropna(inplace=True)  # Drop rows with any NaN values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 10, 20],\n",
        "    'min_samples_leaf': [1, 5, 10],\n",
        "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Perform Grid Search for each target\n",
        "grid_search_v = GridSearchCV(estimator=dtr_v, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search_v.fit(X_train, y_train_v)\n",
        "\n",
        "grid_search_a = GridSearchCV(estimator=dtr_a, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search_a.fit(X_train, y_train_a)\n",
        "\n",
        "grid_search_m = GridSearchCV(estimator=dtr_m, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=2)\n",
        "grid_search_m.fit(X_train, y_train_m)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params_v = grid_search_v.best_params_\n",
        "best_params_a = grid_search_a.best_params_\n",
        "best_params_m = grid_search_m.best_params_\n",
        "\n",
        "# Use the best parameters to initialize the final model\n",
        "dtr_v = DecisionTreeRegressor(**best_params_v)\n",
        "dtr_a = DecisionTreeRegressor(**best_params_a)\n",
        "dtr_m = DecisionTreeRegressor(**best_params_m)\n",
        "\n",
        "# Fit the models with the best parameters\n",
        "dtr_v.fit(X_train, y_train_v)\n",
        "dtr_a.fit(X_train, y_train_a)\n",
        "dtr_m.fit(X_train, y_train_m)\n",
        "\n",
        "# Predict\n",
        "y_pred_v = dtr_v.predict(X_test)\n",
        "y_pred_a = dtr_a.predict(X_test)\n",
        "y_pred_m = dtr_m.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_v = mean_squared_error(y_test_v, y_pred_v)\n",
        "mse_a = mean_squared_error(y_test_a, y_pred_a)\n",
        "mse_m = mean_squared_error(y_test_m, y_pred_m)\n",
        "\n",
        "print(f'Decision Tree Regressor MSE for Vavuniya: {mse_v}')\n",
        "print(f'Decision Tree Regressor MSE for Anuradhapura: {mse_a}')\n",
        "print(f'Decision Tree Regressor MSE for Maha Illuppallama: {mse_m}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj-PbA0GVQTC",
        "outputId": "4d6ceffb-d3ac-4180-cfb5-eff02845f7c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "Decision Tree Regressor MSE for Vavuniya: 124.60631420739274\n",
            "Decision Tree Regressor MSE for Anuradhapura: 160.8274326188902\n",
            "Decision Tree Regressor MSE for Maha Illuppallama: 135.00125369961876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid (same as before)\n",
        "param_grid = {\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 10, 20],\n",
        "    'min_samples_leaf': [1, 5, 10],\n",
        "    'max_features': [None, 'auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Create a dictionary to store best models and parameters\n",
        "best_models = {}\n",
        "best_params = {}\n",
        "\n",
        "# Loop through each target variable\n",
        "target_variables = ['Vavuniya', 'Anuradhapura', 'Maha Illuppallama']\n",
        "for target in target_variables:\n",
        "  # Separate data for the current target\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, df[target], test_size=0.2, random_state=42)\n",
        "\n",
        "  # Create a DecisionTreeRegressor instance\n",
        "  dtr = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "  # Perform Grid Search for the current target\n",
        "  grid_search = GridSearchCV(estimator=dtr, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error', verbose=2)\n",
        "  grid_search.fit(X_train, y_train)\n",
        "\n",
        "  # Store best parameters and model for this target\n",
        "  best_params[target] = grid_search.best_params_\n",
        "  best_models[target] = grid_search.best_estimator_\n",
        "\n",
        "# Use the best parameters to create final models for each target\n",
        "for target, params in best_params.items():\n",
        "  dtr = DecisionTreeRegressor(**params)\n",
        "  dtr.fit(X_train, y_train)\n",
        "  best_models[target] = dtr\n",
        "\n",
        "# Make predictions and evaluate MSE for each target (similar to previous code)\n",
        "for target, model in best_models.items():\n",
        "  y_pred = model.predict(X_test)\n",
        "  mse = mean_squared_error(y_test, y_pred)\n",
        "  print(f'Decision Tree Regressor MSE for {target}: {mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg_543pJX3fg",
        "outputId": "7c9992f3-5985-4481-aeba-928916024a7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "Fitting 3 folds for each of 144 candidates, totalling 432 fits\n",
            "Decision Tree Regressor MSE for Vavuniya: 110.16263101048482\n",
            "Decision Tree Regressor MSE for Anuradhapura: 149.40950080374398\n",
            "Decision Tree Regressor MSE for Maha Illuppallama: 127.03648942550703\n"
          ]
        }
      ]
    }
  ]
}